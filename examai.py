import os
from dotenv import load_dotenv
from supabase import create_client, Client
from typing import List, Optional, Dict, Any
from openai import AsyncOpenAI
import asyncio
import json
from fastapi.concurrency import run_in_threadpool
from fastapi import FastAPI, HTTPException, Header, status, Depends, UploadFile, File
import math

import pypdf 
import tiktoken 
import random # Random import'u da buraya taÅŸÄ±ndÄ±

load_dotenv()
OPENAI_ASSISTANT_ID_ANSWER_CHECKER = os.getenv("OPENAI_ASSISTANT_ID_ANSWER_CHECKER")

# --- Ortam DeÄŸiÅŸkenleri ve KonfigÃ¼rasyon ---
SUPABASE_URL: str = os.getenv("SUPABASE_URL")
SUPABASE_KEY: str = os.getenv("SUPABASE_ANON_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# --- Kontroller ---
if not SUPABASE_URL: raise ValueError("SUPABASE_URL ortam deÄŸiÅŸkeni ayarlanmamÄ±ÅŸ.")
if not SUPABASE_KEY: raise ValueError("SUPABASE_KEY (SUPABASE_ANON_KEY) ortam deÄŸiÅŸkeni ayarlanmamÄ±ÅŸ.")
if not OPENAI_API_KEY: raise ValueError("OPENAI_API_KEY ortam deÄŸiÅŸkeni ayarlanmamÄ±ÅŸ.")

# --- Ä°stemci BaÅŸlatma ---
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
client = AsyncOpenAI(api_key=OPENAI_API_KEY)

# --- ModÃ¼l DosyalarÄ± ve KÃ¶k Dizin ---
PDF_BASE_PATH = os.getenv("PDF_BASE_PATH", "./pdfs") 

MODULE_FILES = {
    "M1": [
        "Launching Appliances Final.pdf",
        "Limit Switch & Fall Wires Types Final.pdf",
        "Release Gear Types Final.pdf",
        "Special Equipments & Tool Types Final.pdf",
        "Survival Craft Engine Types Final.pdf",
        "Survival Craft Types Final.pdf",
        "Winches Final.pdf"
    ],
    "M2": [
        "A-Frame Davit & Fast Rescue Boat Annual Inspections.pdf",
        "Accumulator Control & Refilling Final.pdf",
        "Brake Disassembly & Assembly Operation Final.pdf",
        "Conventional Lifeboat & Davit Annual Inspections Final.pdf",
        "Conventional Lifeboat & Freefall Boat Release Hook Test.pdf",
        "Fast Rescue Boat Hook Overhaul Final.pdf",
        "Freefall Boat & Davit Annual Inspections Final.pdf",
        "Freefall Boat Hook Overhaul Final.pdf",
        "Hydrostatic Interlock Diaphragm Control Final.pdf",
        "Release Cable Adjusting & Timing Set Up Final.pdf",
        "Release Mechanism Overhaul Final.pdf",
        "Rescue Boat & Davit Annual Inspection Final.pdf"
    ],
    "M3": [
        "5 Yearly Inspection for Conventional Lifeboat & Gravity Davit.pdf",
        "5 Yearly Inspection for Freefall Boat & Freefall Davit.pdf",
        "5 Yearly Inspection for Rescue Boat & Rescue Davit.pdf",
        "Load Test Calculation .pdf",
        "Load Test for Conentional Lifeboat & Gravity Davit.pdf",
        "Load Test Procedures for FFB + FFD + LB + LBD + RB + RBD Davit.pdf"
    ]
}

# --- Dosya AdÄ±ndan ModÃ¼l ID'sine EÅŸleme ve Tersine Lookup Map (Case-Insensitive iÃ§in) ---
FILE_TO_MODULE_MAP = {} 
FILE_LOOKUP_MAP = {} 
for mod_id, files_list in MODULE_FILES.items():
    for fname in files_list:
        FILE_TO_MODULE_MAP[fname.upper()] = mod_id
        FILE_LOOKUP_MAP[fname.upper()] = fname 

FILE_NAME_EMBEDDINGS_CACHE: Dict[str, List[float]] = {}


# --- ModÃ¼l BazlÄ± Konu Listeleri (KapsamlÄ±) ---
MODULE_TOPICS = {
    "M1": [
        "Launching Appliance Classifications (Single-Point Suspension)",
        "Launching Appliance Classifications (Two-Point Suspension)",
        "Launching Appliance Classifications (Free-Fall Launch)",
        "Winch Types (Single Drum, Twin Drum, Electric, Hydraulic)",
        "Limit Switch Types (Rotating Spindle, Position, Magnetic) and Functional Roles",
        "Fall Wire Types (Standard Wire Rope, Wedge Socket) and Characteristics",
        "Release Gear Types (On-Load, Off-Load, Combined, Free-Fall Hydraulic)",
        "Survival Craft Types (Lifeboats: Open, Partially Enclosed, Totally Enclosed, Freefall)",
        "Survival Craft Types (Rescue Boats: Rigid, Semi-Rigid Inflatable, Fast)",
        "Survival Craft Engine Types (Inboard, Outboard, Jet Propulsion) and Key Features",
        "Special Tools & Equipment Classification (Hydraulic Power Tools, Mechanical Tools, Diagnostic Tools)",
        "Hydraulic Hand Pumps and Nitrogen Charging Kits",
        "Hook Engagement Indicators and Reset Status Gauges"
    ],
    "M2": [
        "Annual Inspection Protocol (General Purpose and Scope)",
        "Davit Frame and Structure Inspection (Annual)",
        "Hoisting Mechanism Inspection (Annual)",
        "Winch and Brake Assembly Review (Annual)",
        "Brake Disassembly and Assembly Operation",
        "Fall Wire and Sheave Maintenance (Annual, Repositioning, Replacement)",
        "Remote Control and Electrical Components Inspection (Annual)",
        "Hook Mechanism and Release Gear Inspection (Annual FRB)",
        "Fast Rescue Boat Hook Overhaul Procedure",
        "Hydraulic System Inspection (Annual, Davit/Boat Specifics)",
        "Electrical System Checks (Annual, Boat Specifics)",
        "Safety Equipment and Emergency Supplies Inspection (Annual)",
        "Accumulator Control and Refilling Procedure",
        "Hydrostatic Interlock Diaphragm Control",
        "Release Cable Adjusting and Timing Set Up",
        "Release Mechanism Overhaul Procedure (General)",
        "Rescue Boat Annual Inspection Protocol (General)",
        "Rescue Davit Annual Inspection Protocol (General)",
        "Rescue Boat Engine and Propulsion Unit Inspection (Annual)",
        "Rescue Boat Fuel Storage and Delivery System Inspection (Annual)",
        "Rescue Boat Steering System Inspection (Annual)",
        "Lifeboat Outfitting and Safety Equipment Inspection (Annual)",
        "Documentation and Certification Review (Annual Inspections)"
    ],
    "M3": [
        "5-Yearly Inspection Purpose (General)",
        "Load Test Calculation Methodology (Formula, Principles)",
        "Load Test Procedure (Conventional Lifeboat & Gravity Davit)",
        "Load Test Procedure (Freefall Boat & Davit)",
        "Load Test Procedure (Rescue Boat & Davit)",
        "Load Test Safety Considerations (Personnel, PPE, Hazards)",
        "Load Test Documentation and Reporting",
        "Load Test Acceptance Criteria (Structural, Brake, Hydraulic)",
        "5-Yearly Structural Integrity Inspection (Lifeboats/Davits)",
        "5-Yearly Mechanical Systems Inspection (Lifeboats/Davits)",
        "5-Yearly Hydraulic Components Inspection (Lifeboats/Davits)",
        "5-Yearly Safety Fixtures Inspection (Lifeboats/Davits)",
        "5-Yearly Rigging & Cables Inspection (Lifeboats/Davits)",
        "5-Yearly Fastening & Supports Inspection (Lifeboats/Davits)",
        "5-Yearly Winch and Drum Assembly Inspection",
        "5-Yearly Fall Wire System Inspection",
        "5-Yearly Electrical System Inspection",
        "5-Yearly Hook Release Systems Inspection (Freefall)",
        "5-Yearly Engine and Propulsion Unit Inspection (Freefall)", 
        "5-Yearly Fuel Storage and Delivery System Inspection (Freefall)", 
        "5-Yearly Steering System Inspection (Freefall)", 
        "5-Yearly Rescue Boat Inspection Overview",
        "5-Yearly Rescue Davit Inspection Overview",
        "Common Inspection Challenges (Corrosion, Wear, Fatigue)"
    ]
}


# --- YardÄ±mcÄ± Fonksiyonlar ---

# --- Bu yeni fonksiyonu YardÄ±mcÄ± Fonksiyonlar bÃ¶lÃ¼mÃ¼ne ekleyin ---
async def initialize_file_name_embeddings():
    """
    Uygulama baÅŸlangÄ±cÄ±nda tÃ¼m dosya adlarÄ±nÄ±n embedding'lerini oluÅŸturur ve Ã¶nbelleÄŸe alÄ±r.
    """
    print("--- Embedding Ã¶nbelleÄŸi oluÅŸturuluyor... ---")
    file_names_to_embed = list(FILE_LOOKUP_MAP.keys())
    
    try:
        # Toplu halde embedding isteÄŸi gÃ¶nder
        response = await client.embeddings.create(
            input=file_names_to_embed,
            model="text-embedding-3-small"
        )
        
        for i, fname_upper in enumerate(file_names_to_embed):
            FILE_NAME_EMBEDDINGS_CACHE[fname_upper] = response.data[i].embedding
            
        print(f"--- {len(FILE_NAME_EMBEDDINGS_CACHE)} adet dosya adÄ± iÃ§in embedding Ã¶nbelleÄŸi baÅŸarÄ±yla oluÅŸturuldu. ---")
    
    except Exception as e:
        print(f"HATA: Embedding Ã¶nbelleÄŸi oluÅŸturulurken kritik bir hata oluÅŸtu: {e}")
        # Bu kritik bir hata olduÄŸu iÃ§in uygulamayÄ± durdurabilir veya hatayÄ± loglayabilirsiniz.
        raise e

async def _run_openai_assistant(assistant_id: str, user_message_content: str) -> str:
    try:
        # Her Ã§aÄŸrÄ± iÃ§in yeni bir thread oluÅŸturulur
        thread = await client.beta.threads.create()
        await client.beta.threads.messages.create(
            thread_id=thread.id,
            role="user",
            content=user_message_content,
        )

        run = await client.beta.threads.runs.create_and_poll(
            thread_id=thread.id,
            assistant_id=assistant_id,
        )

        if run.status == 'completed':
            messages = await client.beta.threads.messages.list(thread_id=thread.id)
            # AsistanÄ±n son mesajÄ±nÄ± bul
            for message in messages.data:
                if message.role == "assistant":
                    for content_block in message.content:
                        if content_block.type == "text":
                            return content_block.text.value.strip()
            raise ValueError("Asistandan geÃ§erli bir yanÄ±t alÄ±namadÄ±.")
        else:
            raise ValueError(f"Asistan gÃ¶revi tamamlanamadÄ±. Durum: {run.status}")
    except Exception as e:
        print(f"OpenAI Asistan Ã§alÄ±ÅŸtÄ±rÄ±lÄ±rken hata: {e}")
        raise HTTPException(status_code=500, detail=f"OpenAI Asistan yanÄ±t veremedi veya bir hata oluÅŸtu: {e}")

async def _call_openai_chat_model(system_message_content: str, user_message_content: str) -> str:
    print("chat model called")
    try:
        response = await client.chat.completions.create(
            model="gpt-4.1-mini", 
            messages=[
                {"role": "system", "content": system_message_content},
                {"role": "user", "content": user_message_content}
            ],
            temperature=0.7, 
            top_p=1.0,       
            response_format={"type": "json_object"}
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"OpenAI Chat modeli Ã§alÄ±ÅŸtÄ±rÄ±lÄ±rken hata: {e}")
        raise HTTPException(status_code=500, detail=f"OpenAI Chat modeli yanÄ±t veremedi veya bir hata oluÅŸtu: {e}")


async def _call_openai_nano_model_json(system_message_content: str, user_message_content: str) -> str:
    """
    gpt-4o-mini modelini JSON Ã§Ä±ktÄ±sÄ± bekleyerek Ã§aÄŸÄ±ran fonksiyon.
    """
    try:
        response = await client.chat.completions.create(
            model="gpt-4.1-nano",
            messages=[
                {"role": "system", "content": system_message_content},
                {"role": "user", "content": user_message_content}
            ],
            temperature=0.5, # YaratÄ±cÄ±lÄ±k ve tutarlÄ±lÄ±k arasÄ±nda bir denge
            response_format={"type": "json_object"}
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"OpenAI Nano modeli (JSON) Ã§alÄ±ÅŸtÄ±rÄ±lÄ±rken hata: {e}")
        raise HTTPException(status_code=500, detail=f"OpenAI Nano (JSON) modeli yanÄ±t veremedi: {e}")


async def _call_openai_nano_model_text(system_message_content: str, user_message_content: str) -> str:
    """
    gpt-4o-mini modelini dÃ¼z metin Ã§Ä±ktÄ±sÄ± bekleyerek Ã§aÄŸÄ±ran fonksiyon.
    """
    try:
        response = await client.chat.completions.create(
            model="gpt-4.1-nano",
            messages=[
                {"role": "system", "content": system_message_content},
                {"role": "user", "content": user_message_content}
            ],
            temperature=0.7, # Feedback iÃ§in daha doÄŸal bir dil
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"OpenAI Nano modeli (Text) Ã§alÄ±ÅŸtÄ±rÄ±lÄ±rken hata: {e}")
        raise HTTPException(status_code=500, detail=f"OpenAI Nano (Text) modeli yanÄ±t veremedi: {e}")

async def _get_embedding(text: str) -> List[float]:
    try:
        response = await client.embeddings.create(
            input=text,
            model="text-embedding-3-small"
        )
        return response.data[0].embedding
    except Exception as e:
        print(f"Embedding oluÅŸturulurken hata: {e}")
        raise HTTPException(status_code=500, detail=f"Metin embedding'i oluÅŸturulamadÄ±: {e}")

# YENÄ°: Anahtar kelimeyle alakalÄ± dosyalarÄ± bulan semantik arama fonksiyonu
async def _find_relevant_files_by_keyword(keyword_query: str, top_n_files: int = 5) -> List[str]:
    """
    Bir anahtar kelime sorgusuna gÃ¶re, Ã¶nbelleÄŸe alÄ±nmÄ±ÅŸ dosya adÄ± embedding'lerini kullanarak
    en alakalÄ± dosyalarÄ± semantik olarak bulur.
    """
    if not keyword_query:
        return []
    
    # Sadece kullanÄ±cÄ±nÄ±n sorgusu iÃ§in embedding oluÅŸtur
    query_embedding = await _get_embedding(keyword_query)
    
    file_name_similarities = []
    # ArtÄ±k her dosya adÄ± iÃ§in API Ã§aÄŸÄ±rmak yerine Ã¶nbellekten okuyoruz
    for fname_upper, file_name_embedding in FILE_NAME_EMBEDDINGS_CACHE.items():
        similarity_score = sum(q * f for q, f in zip(query_embedding, file_name_embedding))
        
        # Orijinal dosya adÄ±nÄ± FILE_LOOKUP_MAP'ten alÄ±yoruz
        original_file_name = FILE_LOOKUP_MAP.get(fname_upper)
        if original_file_name:
            file_name_similarities.append({"file_name": original_file_name, "similarity": similarity_score})
    
    file_name_similarities.sort(key=lambda x: x['similarity'], reverse=True)
    
    found_files = [item['file_name'] for item in file_name_similarities if item['similarity'] > 0.4][:top_n_files]
            
    return found_files


# _retrieve_relevant_chunks fonksiyonu gÃ¼ncellendi: module_ids listesi ve file_names alacak
# SQL'deki LIMIT kaldÄ±rÄ±ldÄ±ÄŸÄ± iÃ§in tÃ¼m eÅŸleÅŸenler dÃ¶necek
async def _retrieve_relevant_chunks(query_text: str, module_ids: Optional[List[str]] = None, file_names: Optional[List[str]] = None, top_k: int = 50) -> List[Dict[str, Any]]: 
    """
    KullanÄ±cÄ± sorgusuna ve (isteÄŸe baÄŸlÄ±) modÃ¼l ID'leri listesi/dosya adlarÄ± listesine gÃ¶re Supabase'den en alakalÄ± metin parÃ§alarÄ±nÄ± Ã§eker.
    SQL'den tÃ¼m eÅŸleÅŸen parÃ§alarÄ± Ã§eker (LIMIT kaldÄ±rÄ±ldÄ±).
    """
    try:
        print(f"\n--- _retrieve_relevant_chunks baÅŸladÄ±, query_text: '{query_text}', module_ids: '{module_ids}', file_names: '{file_names}' ---")

        query_embedding = await _get_embedding(query_text)
        print(f"--- Embedding alÄ±ndÄ±, boyutu: {len(query_embedding)} ---")

        # Dinamik match_threshold belirleniyor
        current_match_threshold = 0.7 # VarsayÄ±lan olarak yÃ¼ksek (genel arama iÃ§in)
        if (module_ids and len(module_ids) > 0) or (file_names and len(file_names) > 0):
            # EÄŸer modÃ¼l veya dosya filtresi varsa, eÅŸiÄŸi dÃ¼ÅŸÃ¼r (daha fazla parÃ§a Ã§ekmek iÃ§in)
            current_match_threshold = 0.2 # Bu deÄŸer daha Ã¶nce 0.1 idi, testler iÃ§in 0.2 iyi olabilir
            print(f"--- Dinamik EÅŸik: {current_match_threshold} (ModÃ¼l/Dosya Filtresi Aktif) ---")
        else:
            print(f"--- Dinamik EÅŸik: {current_match_threshold} (Genel Arama) ---")


        rpc_args = { 
            'query_embedding': query_embedding,
            'match_threshold': current_match_threshold, # Dinamik eÅŸik kullanÄ±lÄ±yor
            'match_count': top_k # Bu deÄŸer RPC'ye hala gÃ¶nderiliyor, ancak SQL'de LIMIT kaldÄ±rÄ±ldÄ±ÄŸÄ± iÃ§in sadece sÄ±ralama iÃ§in kullanÄ±lÄ±r.
        }
        
        if module_ids and len(module_ids) > 0: 
            rpc_args['match_module_ids'] = [m.upper() for m in module_ids]
            print(f"--- RPC'ye GÃ¶nderilen match_module_ids: {rpc_args['match_module_ids']} ---")
        else:
            rpc_args['match_module_ids'] = None 
            print("--- module_ids filtresi uygulanmadÄ± ---")
        
        if file_names and len(file_names) > 0:
            rpc_args['match_file_names'] = [f.upper() for f in file_names] 
            print(f"--- RPC'ye GÃ¶nderilen match_file_names: {rpc_args['match_file_names']} ---")
        else:
            rpc_args['match_file_names'] = None 
            print("--- file_names filtresi uygulanmadÄ± ---")


        print("--- Supabase RPC Ã§aÄŸrÄ±sÄ± yapÄ±lÄ±yor... ---")

        response = await run_in_threadpool(
            lambda: supabase.rpc('match_chunks', rpc_args).execute() 
        )
        
        print(f"\n--- Supabase'den Gelen Ham YanÄ±t Verisi (response.data) ---")
        print(response.data)
        print("-----------------------------------------------------------\n")
        
        if not response.data:
            return [] # BoÅŸ liste dÃ¶ndÃ¼r
        
        return response.data # DoÄŸrudan Dict listesi dÃ¶ndÃ¼rÃ¼yoruz

    except Exception as e:
        print(f"\n--- _retrieve_relevant_chunks fonksiyonu iÃ§inde yakalanan hata ---")
        print(f"Hata detayÄ±: {e}")
        print("--------------------------------------------------------\n")
        raise HTTPException(status_code=500, detail=f"Bilgi Ã§ekme sÄ±rasÄ±nda hata oluÅŸtu: {e}. Supabase RPC veya embedding servisini kontrol edin.")


# --- Soru Ãœretme FonksiyonlarÄ±nÄ±n GÃ¼ncellenmesi (Her soru iÃ§in ayrÄ± Ã§aÄŸrÄ± ve dinamik konu/dosya seÃ§imi) ---












# examai.py dosyanÄ±za bu yeni fonksiyonu ekleyin

def _post_process_rubric(rubric: Dict[str, Any], question: str) -> Dict[str, Any]:
    """
    Model tarafÄ±ndan Ã¼retilen ham rubriÄŸi alÄ±r ve sorunun doÄŸasÄ±na gÃ¶re
    mantÄ±ksal VE birleÅŸtirmesi ve formatlama yaparak onu mekanik denetime
    %100 uygun hale getirir.
    """
    processed_rubric = {
        "anahtar_kavram": rubric.get("anahtar_kavram", "N/A"),
        "kabul_kriterleri": [],
        "ret_kriterleri": []
    }

    completeness_keywords = [
        'types', 'classifications', 'categories', 'components',
        'differences', 'features', 'roles', 'methods', 'kinds'
    ]
    question_lower = question.lower()
    requires_completeness_check = any(keyword in question_lower for keyword in completeness_keywords)

    kabul_kriterleri_raw = rubric.get("kabul_kriterleri", [])
    if kabul_kriterleri_raw and isinstance(kabul_kriterleri_raw, list):
        formatted_criteria = [f"Cevap, '{str(k).strip()}' ifadesini iÃ§erir." for k in kabul_kriterleri_raw]
        
        if requires_completeness_check and len(formatted_criteria) > 1:
            joined_criteria = " VE ".join([f"({c})" for c in formatted_criteria])
            processed_rubric["kabul_kriterleri"] = [joined_criteria]
        else:
            processed_rubric["kabul_kriterleri"] = formatted_criteria

    ret_kriterleri_raw = rubric.get("ret_kriterleri", [])
    if ret_kriterleri_raw and isinstance(ret_kriterleri_raw, list):
        processed_rubric["ret_kriterleri"] = [
            f"Cevap, '{str(r).strip()}' ifadesini iÃ§erir." for r in ret_kriterleri_raw
        ]

    return processed_rubric


# --- ANA FONKSÄ°YON (NÄ°HAÄ° PROMPT VE AKILLI POST-PROCESSING Ä°LE) ---

async def generate_open_ended_questions_with_rubrics_in_batch(
    number_of_questions: int,
    question_topic: str,
    existing_questions: Optional[List[Dict[str, str]]] = None,
    batch_size: int = 10
) -> Dict[str, Any]:
    """
    Ä°stenen sayÄ±da soruyu ve rubriÄŸi Ã¼retir. Modelin gÃ¶revi en iyi ham
    maddeleri seÃ§mektir; kod ise bu maddeleri kusursuz bir mantÄ±ksal yapÄ±ya
    dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
    """
    if number_of_questions <= 0:
        return {"questions": [], "evaluation_rubrics": []}

    # --- Konu ve Metin HazÄ±rlÄ±ÄŸÄ± (DeÄŸiÅŸiklik yok) ---
    retrieval_query_text = question_topic
    target_module_ids = []
    target_file_names = []
    if question_topic.upper() in MODULE_FILES:
        target_module_ids = [question_topic.upper()]
    elif question_topic.upper() in FILE_LOOKUP_MAP:
        target_file_names = [FILE_LOOKUP_MAP[question_topic.upper()]]
        target_module_ids = [FILE_TO_MODULE_MAP[question_topic.upper()]]
    elif ',' in question_topic:
        parts = [m.strip().upper() for m in question_topic.split(',')]
        for part in parts:
            if part not in MODULE_FILES:
                raise HTTPException(status_code=400, detail=f"GeÃ§ersiz modÃ¼l ID'si: '{part}'.")
            target_module_ids.append(part)
    else:
        found_files_by_keyword = await _find_relevant_files_by_keyword(question_topic, top_n_files=5)
        if found_files_by_keyword:
            target_file_names = found_files_by_keyword
            for fname_original in found_files_by_keyword:
                mod_id = FILE_TO_MODULE_MAP.get(fname_original.upper())
                if mod_id and mod_id not in target_module_ids:
                    target_module_ids.append(mod_id)
        else:
            raise HTTPException(status_code=400, detail=f"GeÃ§ersiz konu/modÃ¼l/dosya: '{question_topic}'.")

    available_topics_for_selection = []
    if target_module_ids:
        for mod_id in target_module_ids:
            if mod_id in MODULE_TOPICS:
                available_topics_for_selection.extend(MODULE_TOPICS[mod_id])
    
    if not available_topics_for_selection:
        raise HTTPException(status_code=404, detail=f"'{question_topic}' ile iliÅŸkili konu bulunamadÄ±.")
    
    all_topics_for_generation = []
    if number_of_questions > len(available_topics_for_selection):
        all_topics_for_generation.extend(available_topics_for_selection * (number_of_questions // len(available_topics_for_selection)))
        all_topics_for_generation.extend(random.sample(available_topics_for_selection, number_of_questions % len(available_topics_for_selection)))
    else:
        all_topics_for_generation = random.sample(available_topics_for_selection, number_of_questions)
    random.shuffle(all_topics_for_generation)

    all_retrieved_chunks_data = await _retrieve_relevant_chunks(retrieval_query_text, module_ids=target_module_ids, file_names=target_file_names, top_k=100)
    if not all_retrieved_chunks_data:
        raise HTTPException(status_code=404, detail="Bilgi kaynaÄŸÄ±nda ilgili metin bulunamadÄ±.")
        
    retrieval_content = ""
    for chunk_data in all_retrieved_chunks_data:
        retrieval_content += f"--- Kaynak: {chunk_data.get('file_name', 'Bilinmiyor')} ---\n{chunk_data['content']}\n\n"
    
    existing_questions_prompt_part = ""
    if existing_questions:
        existing_question_texts = [q['question'] for q in existing_questions if isinstance(q, dict) and 'question' in q]
        existing_questions_str = json.dumps(existing_question_texts, ensure_ascii=False)
        existing_questions_prompt_part = f"\nDAHA Ã–NCE ÃœRETÄ°LMÄ°Åž SORULAR (Bunlardan FARKLI sorular Ã¼retmelisin):\n{existing_questions_str}"

    # --- Batching MantÄ±ÄŸÄ± ve API Ã‡aÄŸrÄ±larÄ± ---
    tasks = []
    num_batches = 1
    if number_of_questions > batch_size:
        num_batches = math.ceil(number_of_questions / batch_size)
    
    topic_batches = [all_topics_for_generation[i::num_batches] for i in range(num_batches)]

    for i, topic_batch in enumerate(topic_batches):
        current_batch_size = len(topic_batch)
        if current_batch_size == 0: continue
        topics_list_str = json.dumps(topic_batch, ensure_ascii=False, indent=2)
        
        # --- NÄ°HAÄ°, BASÄ°TLEÅžTÄ°RÄ°LMÄ°Åž VE DÃœZELTÄ°LMÄ°Åž PROMPT ---
        system_prompt = f"""
GÃ–REV VE KÄ°ÅžÄ°LÄ°K:
Sen, bir "Rubric Derleyicisi (Compiler)" yapay zekasÄ±sÄ±n. GÃ¶revin, sana verilen knowledge_base metnini analiz etmek ve denetÃ§i bir AI iÃ§in yÃ¼ksek kaliteli, ham deÄŸerlendirme verileri (rubric) Ã¼retmektir. Senin gÃ¶revin, en isabetli ve spesifik kanÄ±tlarÄ± seÃ§mektir.

TEMEL PRENSÄ°PLER (DEÄžÄ°ÅžTÄ°RÄ°LEMEZ)
1. KANITA DAYALILIK: SeÃ§tiÄŸin her bir kriter, knowledge_base'den doÄŸrudan alÄ±nabilir, spesifik bir kanÄ±t (teknik terim, sayÄ±, kural vb.) olmalÄ±dÄ±r.
2. NETLÄ°K: SeÃ§tiÄŸin kriterler, belirsiz veya yoruma aÃ§Ä±k olmamalÄ±dÄ±r.
3. BAÄžIMSIZLIK: SeÃ§tiÄŸin her kriter, kendi baÅŸÄ±na bir anlam ifade etmelidir.

ZORUNLU ÃœRETÄ°M SÃœRECÄ°
AÅŸaÄŸÄ±daki adÄ±mlarÄ± istisnasÄ±z ve belirtilen sÄ±rada YÃœRÃœT:

AdÄ±m 1: Soru Ãœretimi
topics_to_cover listesindeki her baÅŸlÄ±k iÃ§in, toplamda {current_batch_size} adet olacak ÅŸekilde, knowledge_base'deki spesifik bilgileri sorgulayan, aÃ§Ä±k uÃ§lu ve Ä°ngilizce sorular Ã¼ret.

AdÄ±m 2: Ham Rubric Verisi Ãœretimi
Her soru iÃ§in aÅŸaÄŸÄ±daki yapÄ±ya harfiyen uyarak bir rubric elemanÄ± oluÅŸtur:
- anahtar_kavram: Konunun en temel prensibini tek bir net cÃ¼mleyle yaz.
- kabul_kriterleri: Soruya doÄŸru cevap veren, birbirinden baÄŸÄ±msÄ±z, en ayÄ±rt edici 2-4 adet spesifik kanÄ±tÄ± bir LÄ°STE olarak yaz.
- ret_kriterleri: knowledge_base ile kanÄ±tlanabilir ÅŸekilde Ã§eliÅŸen veya yaygÄ±n bir yanlÄ±ÅŸÄ± temsil eden 1-2 adet spesifik ifadeyi bir LÄ°STE olarak yaz.

NÄ°HAÄ° UYARI: GÃ¶revin, karmaÅŸÄ±k mantÄ±ksal yapÄ±lar (`VE`/`VEYA`) veya Ã¶zel formatlar (`"Cevap, ... iÃ§erir"`) oluÅŸturmak DEÄžÄ°LDÄ°R. Sadece en kaliteli ve en doÄŸru ham kanÄ±tlarÄ± (anahtar kelimeler, kÄ±sa ifadeler) listelemeye odaklan.

# --- HATA DÃœZELTME: API'nin JSON modu iÃ§in zorunlu olan bÃ¶lÃ¼m eklendi ---
ZORUNLU Ã‡IKTI FORMATI (OUTPUT FORMAT REQUIREMENT)
TÃ¼m Ã§Ä±ktÄ±n, baÅŸka hiÃ§bir metin olmadan, sadece ve sadece geÃ§erli tek bir JSON nesnesi olmalÄ±dÄ±r. Ã‡Ä±ktÄ±nÄ±n tamamÄ± JSON formatÄ±nda olmalÄ±dÄ±r.
# --- HATA DÃœZELTME SONU ---

HEDEFLENEN Ã‡IKTI ÅžABLONU (Bu basit ÅŸablona %100 uy)
{{
  "questions": [
    {{
      "topic": "...",
      "question": "..."
    }}
  ],
  "evaluation_rubrics": [
    {{
      "anahtar_kavram": "Jet sevk sistemleri, farklÄ± yataklar iÃ§in spesifik yaÄŸlama yÃ¶ntemleri kullanÄ±r ve korozyona karÅŸÄ± kurban anotlarla korunur.",
      "kabul_kriterleri": [
        "impeller draws water",
        "steering via waterjet redirection",
        "Forward bearing oil-lubricated",
        "Rear bearing grease-lubricated",
        "sacrificial anodes"
      ],
      "ret_kriterleri": [
        "jet propulsion sistemi iÃ§in propeller kelimesi (doÄŸrusu impeller)",
        "Forward bearing grease-lubricated (doÄŸrularÄ± tam tersidir)"
      ]
    }}
  ]
}}
"""
        user_prompt = f"""
AÅŸaÄŸÄ±daki konu baÅŸlÄ±klarÄ±nÄ±n her biri iÃ§in birer tane olmak Ã¼zere, toplamda {current_batch_size} adet soru ve her biri iÃ§in bir DeÄŸerlendirme Kriteri (Rubric) Ã¼ret:
Konu Listesi (`topics_to_cover`):
{topics_list_str}
{existing_questions_prompt_part}
"""
        tasks.append(_call_openai_chat_model(system_prompt, user_prompt))

    # --- SonuÃ§larÄ± BirleÅŸtirme ve AKILLI POST-PROCESSING ---
    final_questions = []
    final_evaluation_rubrics = []
    try:
        batch_responses = await asyncio.gather(*tasks)
        for i, response_text in enumerate(batch_responses):
            try:
                # Ham JSON Ã§Ä±ktÄ±sÄ±nÄ± ayrÄ±ÅŸtÄ±r
                parsed_response = json.loads(response_text)
                batch_questions = parsed_response.get("questions", [])
                batch_rubrics_raw = parsed_response.get("evaluation_rubrics", [])

                # Gelen verilerin temel doÄŸruluÄŸunu kontrol et
                if not batch_questions or not batch_rubrics_raw or len(batch_questions) != len(topic_batches[i]) or len(batch_questions) != len(batch_rubrics_raw):
                    print(f"Batch {i+1} atlandÄ±: Soru/Rubric sayÄ±sÄ± eÅŸleÅŸmiyor veya veri eksik.")
                    continue

                # Her bir ham rubriÄŸi al ve sorusuyla birlikte iÅŸlemden geÃ§ir
                processed_rubrics_for_batch = []
                for idx, rubric_raw in enumerate(batch_rubrics_raw):
                    question_text = batch_questions[idx]['question']
                    processed_rubric = _post_process_rubric(rubric_raw, question_text)
                    processed_rubrics_for_batch.append(processed_rubric)
                
                final_questions.extend(batch_questions)
                final_evaluation_rubrics.extend(processed_rubrics_for_batch)

            except json.JSONDecodeError:
                print(f"Batch {i+1} atlandÄ±: JSON ayrÄ±ÅŸtÄ±rma hatasÄ±.")
                continue
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Toplu soru ve rubric Ã¼retimi sÄ±rasÄ±nda bir hata oluÅŸtu: {str(e)}")

    # Sorular ve iÅŸlenmiÅŸ rubriklerin sÄ±rasÄ±nÄ±n eÅŸleÅŸtiÄŸinden emin ol
    if len(final_questions) != len(final_evaluation_rubrics):
         raise HTTPException(status_code=500, detail="Son iÅŸleme sonrasÄ± soru ve rubric sayÄ±sÄ± eÅŸleÅŸmiyor.")

    return {"questions": final_questions, "evaluation_rubrics": final_evaluation_rubrics}
















 # examai.py dosyanÄ±za bu yeni fonksiyonu ekleyin

async def generate_multiple_choice_questions_in_batch(
    number_of_questions: int,
    number_of_choices: int,
    question_topic: str,
    existing_questions: Optional[List[str]] = None
) -> Dict[str, Any]:
    
    # --- 1. AdÄ±m: Konu ve Metin ParÃ§acÄ±klarÄ±nÄ± HazÄ±rlama (Bu kÄ±sÄ±m aynÄ±) ---
    
    # ... [Bu bÃ¶lÃ¼m, generate_open_ended_questions_in_batch ile aynÄ±:
    #      RAG ve konu seÃ§imi kodlarÄ± burada da geÃ§erlidir.] ...
    
    retrieval_query_text = question_topic
    target_module_ids = []
    target_file_names = []

    if question_topic.upper() in MODULE_FILES:
        target_module_ids = [question_topic.upper()]
        retrieval_query_text = f"Information about module {question_topic} for exam questions."
    # ... [diÄŸer if/elif/else bloklarÄ±] ...

    available_topics_for_selection = []
    if target_module_ids:
        for mod_id in target_module_ids:
            if mod_id in MODULE_TOPICS:
                available_topics_for_selection.extend(MODULE_TOPICS[mod_id])
    # ... [diÄŸer topic seÃ§imi kodlarÄ±] ...

    if not available_topics_for_selection:
        raise HTTPException(status_code=404, detail=f"'{question_topic}' ile iliÅŸkili konu bulunamadÄ±.")

    topics_for_this_batch = random.sample(available_topics_for_selection, min(number_of_questions, len(available_topics_for_selection)))
    if number_of_questions > len(topics_for_this_batch):
        # Allow repetition if not enough unique topics are available
        topics_for_this_batch.extend(random.choices(available_topics_for_selection, k=number_of_questions - len(topics_for_this_batch)))

    all_retrieved_chunks_data = await _retrieve_relevant_chunks(
        retrieval_query_text, 
        module_ids=target_module_ids, 
        file_names=target_file_names, 
        top_k=100
    )

    if not all_retrieved_chunks_data:
        raise HTTPException(status_code=404, detail="Bilgi kaynaÄŸÄ±nda ilgili metin bulunamadÄ±.")

    # --- 2. AdÄ±m: Tek ve Toplu API Ã‡aÄŸrÄ±sÄ± ---

    retrieval_content = ""
    for chunk_data in all_retrieved_chunks_data: 
        retrieval_content += f"--- Kaynak: {chunk_data.get('file_name', 'Bilinmiyor')} ---\n{chunk_data['content']}\n\n"

    existing_questions_prompt_part = ""
    if existing_questions:
        existing_questions_str = json.dumps(existing_questions, ensure_ascii=False)
        existing_questions_prompt_part = f"\nDAHA Ã–NCE ÃœRETÄ°LMÄ°Åž SORULAR (Bunlardan FARKLI sorular Ã¼retmelisin):\n{existing_questions_str}"

    topics_list_str = "\n".join([f"- {topic}" for topic in topics_for_this_batch])

    system_prompt = f"""
GÃ–REV:
Sen, saÄŸlanan bilgi kaynaÄŸÄ±na (`knowledge_base`) dayanarak, sana verilen konu listesindeki her bir baÅŸlÄ±k iÃ§in BÄ°R TANE olmak Ã¼zere, yÃ¼ksek kaliteli ve birbirinden tamamen farklÄ± Ã§oktan seÃ§meli sÄ±nav sorularÄ± Ã¼reten bir yapay zekasÄ±n.

ðŸŽ¯ AMAÃ‡:
1.  Sana verilen konu listesindeki (`topics_to_cover`) her bir baÅŸlÄ±k iÃ§in, o baÅŸlÄ±kla ilgili, bilgi kaynaÄŸÄ±ndan bir Ã§oktan seÃ§meli soru Ã¼ret.
2.  Her soru iÃ§in {number_of_choices} adet seÃ§enek Ã¼ret.

ðŸ§· KURALLAR (Kritik):
1.  **KONUYA UYUM (EN Ã–NEMLÄ° KURAL):** `topics_to_cover` listesindeki her bir baÅŸlÄ±k iÃ§in **tam olarak bir adet** soru Ã¼retmelisin. Toplamda {number_of_questions} soru Ã¼retmiÅŸ olmalÄ±sÄ±n.
2.  **DOÄžRU CEVAP KONUMU:** `options` listesindeki her bir iÃ§ listede, doÄŸru cevap **her zaman ilk sÄ±rada (indeks 0)** olmalÄ±dÄ±r. DiÄŸer tÃ¼m ÅŸÄ±klar mantÄ±klÄ± ama yanlÄ±ÅŸ Ã§eldiriciler olmalÄ±dÄ±r.
3.  **KAVRAMSAL BAÄžIMSIZLIK:** Ãœretilen her soru farklÄ± bir fikir veya sÃ¼reÃ§ Ã¼zerine olmalÄ±dÄ±r. Daha Ã¶nceki hiÃ§bir soruyla anlamsal olarak %90'dan fazla benzerlik gÃ¶steren veya aynÄ± spesifik detaylarÄ± hedef alan YENÄ° bir soru Ã¼retmek KESÄ°NLÄ°KLE YASAKTIR. Tamamen farklÄ± aÃ§Ä±lardan, farklÄ± alt konulardan veya farklÄ± detaylarÄ± sorgulayan Ã¶zgÃ¼n sorular oluÅŸtur. Bu kurala uyulmamasÄ±, gÃ¶revin tamamen baÅŸarÄ±sÄ±z olduÄŸu anlamÄ±na gelir.
{existing_questions_prompt_part}
4.  **SADECE KAYNAK BÄ°LGÄ°SÄ°:** YalnÄ±zca saÄŸlanan `knowledge_base` metnini kullan.
5.  **Ã‡IKTI FORMATI:** Ã‡Ä±ktÄ±n, `{number_of_questions}` elemanlÄ± bir `questions` listesi ve `{number_of_questions}` elemanlÄ± bir iÃ§ iÃ§e `options` listesi iÃ§eren **tek bir JSON nesnesi** olmalÄ±dÄ±r.

Bilgi KaynaÄŸÄ± (`knowledge_base`):
{retrieval_content}
"""

    user_prompt = f"""
AÅŸaÄŸÄ±daki konu baÅŸlÄ±klarÄ±nÄ±n her biri iÃ§in birer tane olmak Ã¼zere, toplamda {number_of_questions} adet Ã§oktan seÃ§meli soru ve her biri iÃ§in {number_of_choices} ÅŸÄ±k Ã¼ret:

Konu Listesi (`topics_to_cover`):
{topics_list_str}
"""
    
    try:
        response_text = await _call_openai_chat_model(system_prompt, user_prompt)
        parsed_response = json.loads(response_text)

        if not (parsed_response.get("questions") and parsed_response.get("options")):
            raise ValueError("Modelden beklenen formatta veri alÄ±namadÄ±.")
        
        generated_questions = parsed_response["questions"]
        generated_choices = parsed_response["options"]

        if len(generated_questions) != number_of_questions:
            print(f"UYARI: Model beklenen sayÄ±da soru Ã¼retmedi. Beklenen: {number_of_questions}, Ãœretilen: {len(generated_questions)}")
            # Handle mismatch if necessary

        # --- 3. AdÄ±m: ÅžÄ±klarÄ± KarÄ±ÅŸtÄ±rma ve DoÄŸru Cevap Harfini Belirleme ---
        final_choices = []
        final_correct_answers_letter = []

        for choices_list in generated_choices:
            if not choices_list:
                continue

            correct_answer_text = choices_list[0]
            random.shuffle(choices_list)
            
            correct_answer_index = choices_list.index(correct_answer_text)
            correct_answer_letter = chr(ord('A') + correct_answer_index)
            final_correct_answers_letter.append(correct_answer_letter)

            lettered_choices = [f"{chr(ord('A') + i)}) {choice}" for i, choice in enumerate(choices_list)]
            final_choices.append(lettered_choices)

        return {
            "questions": generated_questions,
            "choices": final_choices,
            "correct_answers": final_correct_answers_letter
        }

    except Exception as e:
        print(f"Toplu Ã§oktan seÃ§meli soru Ã¼retiminde hata oluÅŸtu: {e}")
        raise HTTPException(status_code=500, detail=f"Toplu Ã§oktan seÃ§meli soru Ã¼retimi sÄ±rasÄ±nda bir hata oluÅŸtu: {e}")




async def generate_verbal_questions(
    number_of_questions: int, 
    question_topic: str, 
    existing_questions: Optional[List[str]] = None
) -> Dict[str, List[str]]:
    
    # Retrieval iÃ§in kullanÄ±lacak sorgu metni ve filtreleri belirle
    retrieval_query_text = question_topic 
    target_module_ids = [] 
    target_file_names = [] 

    # question_topic'i yorumla... (Bu bÃ¶lÃ¼m generate_open_ended ile aynÄ±)
    if question_topic.upper() in MODULE_FILES:
        target_module_ids = [question_topic.upper()]
        retrieval_query_text = f"Information about the content and key concepts of module {question_topic} for verbal exam questions."
    elif question_topic.upper() in FILE_LOOKUP_MAP:
        target_file_names = [FILE_LOOKUP_MAP[question_topic.upper()]]
        target_module_ids = [FILE_TO_MODULE_MAP[question_topic.upper()]] 
        retrieval_query_text = f"Information for verbal exam questions from file {question_topic}."
    elif ',' in question_topic:
        parts = [m.strip().upper() for m in question_topic.split(',')]
        for part in parts:
            if part not in MODULE_FILES:
                raise HTTPException(status_code=400, detail=f"GeÃ§ersiz modÃ¼l ID'si: '{part}'.")
            target_module_ids.append(part)
        retrieval_query_text = f"Information for verbal exam questions from modules {question_topic}."
    else:
        print(f"DEBUG: '{question_topic}' anahtar kelime olarak yorumlanÄ±yor...")
        found_files_by_keyword = await _find_relevant_files_by_keyword(question_topic, top_n_files=5)
        
        if found_files_by_keyword:
            target_file_names = found_files_by_keyword
            for fname_original in found_files_by_keyword:
                mod_id = FILE_TO_MODULE_MAP.get(fname_original.upper())
                if mod_id and mod_id not in target_module_ids:
                    target_module_ids.append(mod_id)
            retrieval_query_text = f"Information for verbal exam questions related to '{question_topic}' from files: {', '.join(found_files_by_keyword)}."
        else:
            raise HTTPException(status_code=400, detail=f"GeÃ§ersiz konu/modÃ¼l/dosya: '{question_topic}'.")
    
    available_topics_for_selection = []
    if target_module_ids: 
        for mod_id in target_module_ids:
            if mod_id in MODULE_TOPICS:
                available_topics_for_selection.extend(MODULE_TOPICS[mod_id])
    elif target_file_names:
        for fname_original in target_file_names:
            mod_id = FILE_TO_MODULE_MAP.get(fname_original.upper())
            if mod_id and mod_id in MODULE_TOPICS:
                available_topics_for_selection.extend(MODULE_TOPICS[mod_id])
    
    if not available_topics_for_selection:
        raise HTTPException(status_code=404, detail=f"'{question_topic}' ile iliÅŸkili konu bulunamadÄ±.")

    if number_of_questions > len(available_topics_for_selection):
        topics_for_this_batch = random.sample(available_topics_for_selection, len(available_topics_for_selection)) * (number_of_questions // len(available_topics_for_selection))
        topics_for_this_batch.extend(random.sample(available_topics_for_selection, number_of_questions % len(available_topics_for_selection)))
        random.shuffle(topics_for_this_batch) 
    else:
        topics_for_this_batch = random.sample(available_topics_for_selection, number_of_questions)
        
    all_retrieved_chunks_data = await _retrieve_relevant_chunks(
        retrieval_query_text, 
        module_ids=target_module_ids, 
        file_names=target_file_names, 
        top_k=50 
    ) 

    if not all_retrieved_chunks_data:
        raise HTTPException(status_code=404, detail="Bilgi kaynaÄŸÄ±nda ilgili metin bulunamadÄ±.")
    
    existing_questions_prompt_part = ""
    if existing_questions:
        existing_questions_str = json.dumps(existing_questions, ensure_ascii=False, indent=2)
        existing_questions_prompt_part = f"\nDAHA Ã–NCE ÃœRETÄ°LMÄ°Åž SORULAR (Bunlardan FARKLI sorular Ã¼retmelisin):\n{existing_questions_str}"

    generated_questions = []
    generated_feedback_guides = []
    
    max_attempts_per_question = 3 
    
    for i, selected_topic_for_this_question in enumerate(topics_for_this_batch):
        attempt = 0
        question_generated_successfully = False
        
        while attempt < max_attempts_per_question and not question_generated_successfully:
            attempt += 1
            
            num_chunks_for_question = min(random.randint(5, 10), len(all_retrieved_chunks_data)) 
            random_chunks_for_this_question = random.sample(all_retrieved_chunks_data, num_chunks_for_question)
            
            retrieval_content_for_this_question = ""
            for chunk_data in random_chunks_for_this_question: 
                retrieval_content_for_this_question += f"--- Kaynak: {chunk_data.get('file_name', 'Bilinmiyor')} ---\n{chunk_data['content']}\n\n"

            verbal_question_prompt = f"""
GÃ–REV:
Sen, bir denizcilik akademisinde sÃ¶zlÃ¼ sÄ±navlar hazÄ±rlayan uzman bir eÄŸitmensin. GÃ¶revin, bir Ã¶ÄŸrencinin bilgisini derinlemesine Ã¶lÃ§en, 1-2 dakikalÄ±k sÃ¶zel bir cevap gerektiren sorular hazÄ±rlamak ve bu sorularÄ± deÄŸerlendirecek baÅŸka bir eÄŸitmen iÃ§in detaylÄ± bir geri bildirim rehberi (`feedback_guide`) oluÅŸturmaktÄ±r.
SORU STÄ°LÄ° (KRÄ°TÄ°K):
Sorular, basit bir evet/hayÄ±r veya tek kelimelik cevapla geÃ§iÅŸtirilememelidir. Ã–ÄŸrenciyi bir prosedÃ¼rÃ¼ anlatmaya, bir sistemi aÃ§Ä±klamaya veya kavramlarÄ± karÅŸÄ±laÅŸtÄ±rmaya teÅŸvik etmelidir.
* **KullanÄ±lacak ifadeler:** "Explain...", "Describe the process of...", "Compare and contrast...", "Walk me through the steps for..."
* **Ã–zellikle '{selected_topic_for_this_question}' konusuyla ilgili bir soru Ã¼retmelisin.**
{existing_questions_prompt_part}
GERÄ° BÄ°LDÄ°RÄ°M REHBERÄ° (`correct_answers`) STÄ°LÄ° (KRÄ°TÄ°K):
`correct_answers` alanÄ±, bir "ideal cevap" metni DEÄžÄ°LDÄ°R. Bu, bir insan eÄŸitmene, Ã¶ÄŸrencinin cevabÄ±nÄ± deÄŸerlendirirken nelere dikkat etmesi gerektiÄŸini anlatan bir **yol haritasÄ±dÄ±r**.
* **Ä°Ã§erik:** Ã–ÄŸrencinin cevabÄ±nda bahsetmesi beklenen **tÃ¼m anahtar kavramlarÄ±, teknik terimleri, prosedÃ¼r adÄ±mlarÄ±nÄ± ve kritik gÃ¼venlik notlarÄ±nÄ±** madde madde listele.
* **Format:** AÃ§Ä±k ve anlaÅŸÄ±lÄ±r olmasÄ± iÃ§in maddeleme (`-` veya `*`) kullan.
ZORUNLU Ã‡IKTI FORMATI:
Ã‡Ä±ktÄ±n, **kesinlikle ve sadece** `questions` ve `correct_answers` anahtarlarÄ±nÄ± iÃ§eren geÃ§erli bir JSON olmalÄ±dÄ±r.
Bilgi KaynaÄŸÄ± Metni:
{retrieval_content_for_this_question}
"""
            
            user_message = f"YukarÄ±daki talimatlara gÃ¶re 1 adet sÃ¶zel soru ve geri bildirim rehberi Ã¼ret."
            
            try:
                response_text = await _call_openai_nano_model_json(verbal_question_prompt, user_message)
                parsed_response = json.loads(response_text)
                
                if parsed_response.get("questions") and parsed_response.get("correct_answers"):
                    generated_questions.extend(parsed_response["questions"])
                    generated_feedback_guides.extend(parsed_response["correct_answers"])
                    question_generated_successfully = True
                else:
                    print(f"UYARI: Nano model sÃ¶zel soru Ã¼retiminde boÅŸ liste dÃ¶ndÃ¼. Soru indeksi: {i}, Deneme: {attempt}")
            except Exception as e:
                print(f"UYARI: Nano model ile sÃ¶zel soru Ã¼retiminde hata oluÅŸtu. Soru indeksi: {i}, Deneme: {attempt}, Hata: {e}")
        
        if not question_generated_successfully:
            print(f"HATA: SÃ¶zel Soru {i+1} iÃ§in {max_attempts_per_question} denemede baÅŸarÄ±lÄ± soru Ã¼retilemedi.")
            
    if len(generated_questions) != number_of_questions:
        raise HTTPException(status_code=500, detail=f"Beklenen sÃ¶zel soru sayÄ±sÄ± ({number_of_questions}) Ã¼retilemedi. Ãœretilen: {len(generated_questions)}.")

    return {
        "questions": generated_questions,
        "correct_answers": generated_feedback_guides
    }


# --- Cevap Kontrol Fonksiyonunun GÃ¼ncellenmesi (DoÄŸrudan Prompt Sistemi) ---
import json
from typing import List
from fastapi import HTTPException














async def provide_feedback_on_verbal_answers(
    questions: List[str],
    feedback_guides: List[str], # Bunlar veritabanÄ±nÄ±n 'correct_answers' sÃ¼tunundan gelecek
    student_verbal_answers: List[str]
) -> List[str]:

    final_feedbacks = []
    
    tasks = []
    for i in range(len(questions)):
        feedback_provider_prompt = f"""
GÃ–REV VE KÄ°ÅžÄ°LÄ°K:
Sen, bir denizcilik akademisinde eÄŸitmen asistanÄ± olan, yardÄ±msever bir yapay zekasÄ±n. GÃ¶revin, bir Ã¶ÄŸrencinin sÃ¶zlÃ¼ sÄ±nav cevabÄ±nÄ±, sana verilen geri bildirim rehberine (`feedback_guide`) gÃ¶re analiz etmek ve bu analizi, nihai deÄŸerlendirmeyi yapacak olan insan eÄŸitmene sunulmak Ã¼zere yapÄ±cÄ± bir geri bildirim metni olarak Ã¶zetlemektir.

ZORUNLU Ã‡IKTI FORMATI (KRÄ°TÄ°K):
Ã‡Ä±ktÄ±n, **kÄ±sa, net ve konunun Ã¶zÃ¼ne odaklanmalÄ±dÄ±r.** CevabÄ±n **kesinlikle yeni satÄ±r karakteri (`\\n`) iÃ§ermemelidir.** CevabÄ±, aÅŸaÄŸÄ±daki baÅŸlÄ±klarÄ± kullanarak tek bir paragraf halinde yaz. **Her bÃ¶lÃ¼m iÃ§in en fazla 1-2 madde belirt.**

GÄ°RDÄ°LER:
* `question`: Ã–ÄŸrenciye sorulan soru.
* `student_answer`: Ã–ÄŸrencinin (sesinden yazÄ±ya dÃ¶kÃ¼lmÃ¼ÅŸ) cevabÄ±.
* `feedback_guide`: Ã–ÄŸrencinin cevabÄ±nda olmasÄ± beklenen anahtar noktalarÄ± listeleyen rehber.

SENÄ°N GÃ–REVÄ°N:
Ã–ÄŸrencinin cevabÄ±nÄ± rehberle karÅŸÄ±laÅŸtÄ±r. **Asla `correct` veya `wrong` gibi bir yargÄ±da bulunma.** Sadece objektif bir analiz sun.

ZORUNLU Ã‡IKTI FORMATI (KRÄ°TÄ°K):
Ã‡Ä±ktÄ±n, **kÄ±sa, net ve konunun Ã¶zÃ¼ne odaklanmalÄ±dÄ±r.** CevabÄ±n **kesinlikle yeni satÄ±r karakteri (`\\n`) iÃ§ermemelidir.** Bunun yerine, her bÃ¶lÃ¼mÃ¼ baÅŸlÄ±klarla ayÄ±rarak tek bir paragraf halinde yaz.

FORMAT ÅžÃ–YLE OLMALIDIR:
**GÃ¼Ã§lÃ¼ YÃ¶nler:** (Ã–ÄŸrencinin, rehberdeki hangi noktalara doÄŸru bir ÅŸekilde deÄŸindiÄŸini 1-2 cÃ¼mleyle Ã¶zetle.) **GeliÅŸtirilebilecek YÃ¶nler:** (Ã–ÄŸrencinin, rehberdeki hangi Ã¶nemli noktalarÄ± atladÄ±ÄŸÄ±nÄ± veya yanlÄ±ÅŸ aÃ§Ä±kladÄ±ÄŸÄ±nÄ± 1-2 cÃ¼mleyle Ã¶zetle.) **Genel Ã–zet:** (Ã–ÄŸrencinin konuyu anlama seviyesi hakkÄ±nda tek bir cÃ¼mlelik genel bir yorum yap.)
"""
        
        user_message = f"""
        AÅŸaÄŸÄ±daki verileri kullanarak geri bildirim metnini oluÅŸtur:

        Soru: {questions[i]}
        
        Geri Bildirim Rehberi (Beklenenler):
        {feedback_guides[i]}

        Ã–ÄŸrencinin CevabÄ±:
        {student_verbal_answers[i]}
        """
        tasks.append(_call_openai_nano_model_text(feedback_provider_prompt, user_message))

    try:
        # TÃ¼m geri bildirim gÃ¶revlerini eÅŸ zamanlÄ± olarak Ã§alÄ±ÅŸtÄ±r
        final_feedbacks = await asyncio.gather(*tasks)
    except Exception as e:
        print(f"Geri bildirim Ã¼retilirken kritik bir asyncio hatasÄ± oluÅŸtu: {e}")
        raise HTTPException(status_code=500, detail=f"Geri bildirim Ã¼retilirken bir hata oluÅŸtu: {e}")

    return final_feedbacks



# --- VeritabanÄ± Ä°ÅŸlemleri (exam_name EKLENEREK GÃœNCELLENDÄ°) ---

async def get_student_exam_record(exam_name: str, student_name: str, question_type: str) -> dict | None:
    """Belirtilen sÄ±nav adÄ±, Ã¶ÄŸrenci ve soru tipi iÃ§in tek bir sÄ±nav kaydÄ±nÄ± getirir."""
    try:
        response = await run_in_threadpool(
            lambda: supabase.table('exam_records')
            .select("*")
            .eq("exam_name", exam_name)
            .eq("student_name", student_name)
            .eq("question_type", question_type)
            .single()
            .execute()
        )
        return response.data
    except Exception as e:
        if "PGRST" in str(e) and "0 rows" in str(e):
            return None
        print(f"SÄ±nav kaydÄ± alÄ±nÄ±rken hata oluÅŸtu: {e}")
        return None

async def upsert_exam_record(record_data: Dict[str, Any]) -> Dict[str, Any] | None:
    """Bir sÄ±nav kaydÄ±nÄ± ekler veya gÃ¼nceller. Ã‡akÄ±ÅŸma durumu (exam_name, student_name, question_type) ile kontrol edilir."""
    try:
        if not all(k in record_data for k in ['exam_name', 'student_name', 'question_type']):
            raise ValueError("upsert_exam_record iÃ§in exam_name, student_name ve question_type zorunludur.")
            
        response = await run_in_threadpool(
            lambda: supabase.table('exam_records')
            .upsert(record_data, on_conflict='exam_name,student_name,question_type')
            .execute()
        )
        return response.data[0]
    except Exception as e:
        print(f"SÄ±nav kaydÄ± eklenirken/gÃ¼ncellenirken hata oluÅŸtu: {e}")
        return None

async def update_all_questions_in_record(exam_name: str, student_name: str, question_type: str, new_questions: List[str], new_correct_answers: Optional[List[str]] = None) -> dict | None:
    record = await get_student_exam_record(exam_name, student_name, question_type)
    if not record:
        record = {"exam_name": exam_name, "student_name": student_name, "question_type": question_type}

    record['questions'] = new_questions
    
    if new_correct_answers is not None:
        if len(new_questions) != len(new_correct_answers):
            raise ValueError("Soru sayÄ±sÄ± ile doÄŸru cevap sayÄ±sÄ± eÅŸleÅŸmelidir.")
        record['correct_answers'] = new_correct_answers
    
    return await upsert_exam_record(record)

async def update_all_choices_in_record(exam_name: str, student_name: str, question_type: str, all_new_choices: List[List[str]]) -> dict | None:
    record = await get_student_exam_record(exam_name, student_name, question_type)
    if not record:
        record = {"exam_name": exam_name, "student_name": student_name, "question_type": question_type}

    record['choices'] = all_new_choices
    
    return await upsert_exam_record(record)

async def update_answer(exam_name: str, student_name: str, question_type: str, index: int, answer: str) -> dict | None:
    record = await get_student_exam_record(exam_name, student_name, question_type)
    
    if not record:
        record = {"exam_name": exam_name, "student_name": student_name, "question_type": question_type, "answers": []}

    answers = record.get('answers')
    if not isinstance(answers, list):
        answers = []
        record['answers'] = answers

    while len(answers) <= index:
        answers.append(None)

    answers[index] = answer
    
    record['answers'] = answers
    
    return await upsert_exam_record(record)

async def update_answers_bulk(exam_name: str, student_name: str, question_type: str, new_answers: List[str]) -> dict | None:
    return await upsert_exam_record({
        "exam_name": exam_name,
        "student_name": student_name,
        "question_type": question_type,
        "answers": new_answers
    })

async def update_results_bulk(exam_name: str, student_name: str, question_type: str, new_results: List[str]) -> dict | None:
    return await upsert_exam_record({
        "exam_name": exam_name,
        "student_name": student_name,
        "question_type": question_type,
        "results": new_results
    })

async def update_plagiarism_violations_in_record(exam_name: str, student_name: str, question_type: str, violation_text: str) -> dict | None:
    return await upsert_exam_record({
        "exam_name": exam_name,
        "student_name": student_name,
        "question_type": question_type,
        "plagiarism_violations": violation_text
    })

async def get_questions_all(exam_name: str, student_name: str, question_type: str) -> List[str] | None:
    record = await get_student_exam_record(exam_name, student_name, question_type)
    return record.get('questions') if record and isinstance(record.get('questions'), list) else None

async def get_answers_all(exam_name: str, student_name: str, question_type: str) -> List[str] | None:
    record = await get_student_exam_record(exam_name, student_name, question_type)
    return record.get('answers') if record and isinstance(record.get('answers'), list) else None

async def get_results_all(exam_name: str, student_name: str, question_type: str) -> List[str] | None:
    record = await get_student_exam_record(exam_name, student_name, question_type)
    return record.get('results') if record and isinstance(record.get('results'), list) else None

async def get_total_score(exam_name: str, student_name: str, question_type: str) -> float | None:
    record = await get_student_exam_record(exam_name, student_name, question_type)
    return record.get('total_score') if record and 'total_score' in record else None

async def get_plagiarism_violations(exam_name: str, student_name: str, question_type: str) -> str | None:
    record = await get_student_exam_record(exam_name, student_name, question_type)
    return record.get('plagiarism_violations') if record and 'plagiarism_violations' in record else None


async def update_all_correct_answers_in_record(exam_name: str, student_name: str, question_type: str, new_correct_answers: List[str]) -> dict | None:
    """Bir sÄ±navdaki tÃ¼m doÄŸru cevaplarÄ± toplu olarak gÃ¼nceller."""
    record = await get_student_exam_record(exam_name, student_name, question_type)
    if not record:
        record = {"exam_name": exam_name, "student_name": student_name, "question_type": question_type}
    
    record['correct_answers'] = new_correct_answers
    return await upsert_exam_record(record)

async def get_correct_answers_all(exam_name: str, student_name: str, question_type: str) -> List[str] | None:
    """Bir sÄ±navdaki tÃ¼m doÄŸru cevaplarÄ± dÃ¶ndÃ¼rÃ¼r."""
    record = await get_student_exam_record(exam_name, student_name, question_type)
    return record.get('correct_answers') if record and isinstance(record.get('correct_answers'), list) else None

async def delete_single_question(exam_name: str, student_name: str, question_type: str, index: int) -> dict | None:
    """Belirtilen indeksteki bir soruyu ve ilgili tÃ¼m verilerini siler."""
    record = await get_student_exam_record(exam_name, student_name, question_type)
    if not record:
        return None

    questions = record.get('questions')
    
    if not questions:
        raise ValueError("Silinecek soru bulunmuyor (soru listesi boÅŸ).")
        
    if not (0 <= index < len(questions)):
        raise ValueError(f"GeÃ§ersiz indeks: {index}. Soru sayÄ±sÄ±: {len(questions)}.")

    for key in ['questions', 'correct_answers', 'answers', 'results', 'choices']:
        if key in record and isinstance(record.get(key), list) and index < len(record[key]):
            record[key].pop(index)

    return await upsert_exam_record(record)


async def delete_all_questions(exam_name: str, student_name: str, question_type: str) -> dict | None:
    """Belirtilen sÄ±nav tÃ¼rÃ¼ndeki tÃ¼m sorularÄ± ve ilgili verileri null olarak ayarlar."""
    record = await get_student_exam_record(exam_name, student_name, question_type)
    if not record:
        return None

    if not record.get('questions'):
        raise ValueError("Silinecek soru bulunmuyor (soru listesi zaten boÅŸ).")

    record['questions'] = None
    record['correct_answers'] = None
    record['answers'] = None
    record['results'] = None
    record['choices'] = None
    record['total_score'] = None

    return await upsert_exam_record(record)

# main.py'deki Ã§aÄŸÄ±rma uyumluluÄŸunu saÄŸlamak iÃ§in eklenen/gÃ¼ncellenen fonksiyonlar
async def get_question(exam_name: str, student_name: str, question_type: str, index: int) -> str | None:
    record = await get_student_exam_record(exam_name, student_name, question_type)
    if record and isinstance(record.get('questions'), list) and index < len(record['questions']):
        return record['questions'][index]
    return None

async def get_choice(exam_name: str, student_name: str, question_type: str, question_index: int, choice_index: int) -> str | None:
    record = await get_student_exam_record(exam_name, student_name, question_type)
    if record and isinstance(record.get('choices'), list) and question_index < len(record['choices']):
        if isinstance(record['choices'][question_index], list) and choice_index < len(record['choices'][question_index]):
            return record['choices'][question_index][choice_index]
    return None

async def update_question_in_record(exam_name: str, student_name: str, question_type: str, question_index: int, value: str, correct_answer: Optional[str] = None) -> dict | None:
    record = await get_student_exam_record(exam_name, student_name, question_type)
    if not record:
        return None

    questions = record.get('questions', [])
    if not isinstance(questions, list):
        questions = []
    while len(questions) <= question_index:
        questions.append(None)
    questions[question_index] = value
    record['questions'] = questions

    if correct_answer is not None:
        correct_answers = record.get('correct_answers', [])
        if not isinstance(correct_answers, list):
            correct_answers = []
        while len(correct_answers) <= question_index:
            correct_answers.append(None)
        correct_answers[question_index] = correct_answer
        record['correct_answers'] = correct_answers

    return await upsert_exam_record(record)

async def update_choice_in_record(exam_name: str, student_name: str, question_type: str, question_index: int, choice_index: int, value: str) -> dict | None:
    record = await get_student_exam_record(exam_name, student_name, question_type)
    if not record or not isinstance(record.get('choices'), list):
        return None

    choices = record['choices']
    if not (isinstance(choices, list) and question_index < len(choices) and isinstance(choices[question_index], list) and choice_index < len(choices[question_index])):
        return None
    
    choices[question_index][choice_index] = value
    record['choices'] = choices

    return await upsert_exam_record(record)

async def update_choices_for_single_question_in_record(exam_name: str, student_name: str, question_type: str, question_index: int, new_choices: List[str]) -> dict | None:
    record = await get_student_exam_record(exam_name, student_name, question_type)
    if not record or not isinstance(record.get('choices'), list):
        return None

    choices = record.get('choices', [])
    while len(choices) <= question_index:
        choices.append([])
    choices[question_index] = new_choices
    record['choices'] = choices
    
    return await upsert_exam_record(record)

async def update_correct_answer_in_record(exam_name: str, student_name: str, question_type: str, index: int, correct_answer: str) -> dict | None:
    """Belirli bir sorunun doÄŸru cevabÄ±nÄ± gÃ¼nceller."""
    record = await get_student_exam_record(exam_name, student_name, question_type)
    if not record:
        return None

    correct_answers = record.get('correct_answers', [])
    if not isinstance(correct_answers, list):
        correct_answers = []
    
    while len(correct_answers) <= index:
        correct_answers.append(None)
        
    correct_answers[index] = correct_answer
    record['correct_answers'] = correct_answers
    
    return await upsert_exam_record(record)

async def update_result(exam_name: str, student_name: str, question_type: str, index: int, result: str) -> dict | None:
    record = await get_student_exam_record(exam_name, student_name, question_type)
    if not record or not isinstance(record.get('results'), list):
        if not record:
            record = {"exam_name": exam_name, "student_name": student_name, "question_type": question_type, "results": []}
        else:
            record['results'] = []
    
    results = record['results']
    while len(results) <= index:
        results.append(None)

    results[index] = result
    record['results'] = results
    return await upsert_exam_record(record)


from openai import AsyncOpenAI # Make sure AsyncOpenAI is imported
# new import for file handling
import io 

# existing client setup
# supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
client = AsyncOpenAI(api_key=OPENAI_API_KEY) # Make sure this line exists and is correct

# --- NEW: Function to handle voice answers ---

async def add_voice_answer(
    exam_name: str,
    student_name: str,
    index: int,
    audio_file: io.BytesIO # io.BytesIO tipinde bir dosya objesi bekliyoruz
) -> str:
    """
    Verilen ses dosyasÄ±nÄ± OpenAI Whisper kullanarak metne Ã§evirir ve
    belirli bir sÄ±nav kaydÄ±ndaki cevabÄ± gÃ¼nceller.
    question_type'Ä±n 'Verbal Question' olmasÄ± beklenir.
    """
    # 1. Ses dosyasÄ±nÄ± metne Ã§evirmek iÃ§in Whisper API'Ä±nÄ± kullan
    # In examai.py, inside the add_voice_answer function:

    # In examai.py, inside the add_voice_answer function:

    try:
        transcription = await client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            response_format="text"
        )
        transcribed_text = transcription.strip() # CORRECTED LINE: Directly use 'transcription' as it's already the string
        if not transcribed_text:
            raise ValueError("Ses metne Ã§evrilemedi veya boÅŸ bir metin dÃ¶ndÃ¼rÃ¼ldÃ¼.")

    except Exception as e:
        print(f"Whisper API hatasÄ±: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Ses metne Ã§evrilirken hata oluÅŸtu: {e}")
    
    # 2. Metne Ã§evrilen cevabÄ± veri tabanÄ±na kaydet
    try:
        # update_answer fonksiyonunu kullanarak cevabÄ± gÃ¼ncelliyoruz
        # question_type'Ä± "Verbal Question" olarak sabitliyoruz.
        updated_record = await update_answer(
            exam_name=exam_name,
            student_name=student_name,
            question_type="Verbal Question", # Bu kÄ±sÄ±m sabit!
            index=index,
            answer=transcribed_text
        )

        if not updated_record:
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="SÄ±nav kaydÄ± bulunamadÄ±ÄŸÄ± iÃ§in sesli cevap kaydedilemedi.")
            
        return transcribed_text

    except HTTPException as e:
        raise e
    except Exception as e:
        print(f"Veri tabanÄ±na sesli cevap kaydedilirken hata: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Sesli cevap veri tabanÄ±na kaydedilirken hata oluÅŸtu: {e}")
    



async def check_answers_in_batch_with_rubrics(
    questions_with_topics: List[Dict[str, str]],
    evaluation_rubrics: List[Dict],
    answers: List[str],
    batch_size: int = 10
) -> Dict[str, List[str]]:
    """
    CevaplarÄ±, her soru iÃ§in Ã¶zel olarak Ã¼retilmiÅŸ ve VE/VEYA mantÄ±ÄŸÄ± iÃ§erebilen
    bir Rubric kullanarak toplu halde deÄŸerlendirir. Bu versiyon, en geliÅŸmiÅŸ
    deÄŸerlendirme mantÄ±ÄŸÄ±nÄ± kullanÄ±r.
    """
    
    all_data = list(zip(questions_with_topics, evaluation_rubrics, answers))
    batches = [all_data[i:i + batch_size] for i in range(0, len(all_data), batch_size)]
    
    print(f"\n--- Rubric ile Toplu DeÄŸerlendirme BaÅŸladÄ±: {len(questions_with_topics)} soru, {len(batches)} parÃ§a... ---")

    tasks = []
    
    # --- DEÄžÄ°ÅžÄ°KLÄ°K BURADA BAÅžLIYOR: ESKÄ° PROMPT, NÄ°HAÄ° PROMPT Ä°LE DEÄžÄ°ÅžTÄ°RÄ°LDÄ° ---
    
    auditor_system_prompt = """
GÃ–REV VE KÄ°ÅžÄ°LÄ°K:
Sen, adÄ± 'AuditorAI' olan, duygusal olmayan, son derece tutarlÄ± ve sadece saÄŸlanan kanÄ±tlara dayanan bir denetim yapay zekasÄ±sÄ±n. GÃ¶revin, bir Ã¶ÄŸrenci cevabÄ±nÄ±, sana verilen spesifik DeÄŸerlendirme Kriterleri'ne (Rubric) gÃ¶re analiz ederek cevabÄ±n yeterliliÄŸini ve bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ deÄŸerlendirmektir.

GÄ°RDÄ°LER:
Sana her zaman Ã¼Ã§ anahtar bilgi verilecek:
1.  question: Ä°Ã§inde hem `topic` (konu baÅŸlÄ±ÄŸÄ±) hem de `question` (soru metni) bulunan bir JSON nesnesi.
2.  student_answer: Ã–ÄŸrencinin verdiÄŸi cevap.
3.  evaluation_rubric: CevabÄ± deÄŸerlendirmek iÃ§in kullanacaÄŸÄ±n kriterler (`anahtar_kavram`, `kabul_kriterleri`, `ret_kriterleri`).

ZORUNLU KARAR VERME ALGORÄ°TMASI (TARTIÅžMASIZ):
Her bir Ã¶ÄŸrenci cevabÄ±nÄ± deÄŸerlendirirken aÅŸaÄŸÄ±daki adÄ±mlarÄ± kesinlikle bu sÄ±rayla izleyeceksin:

AdÄ±m 1: Ret Kriterlerini Kontrol Et (Kesin Ret AdÄ±mÄ±)
Ã–ÄŸrencinin cevabÄ±nÄ± dikkatlice oku ve `ret_kriterleri` listesindeki maddelerden herhangi birini tetikleyip tetiklemediÄŸini kontrol et.
* EÄŸer cevap, `ret_kriterleri` listesindeki maddelerden BÄ°RÄ°NÄ° BÄ°LE tetikliyorsa, dÃ¼ÅŸÃ¼nmeyi anÄ±nda durdur. Karar `wrong` olmalÄ±dÄ±r. GerekÃ§e olarak tetiklenen ret kriterini belirt.

AdÄ±m 2: Kabul Kriterlerini AyrÄ±ÅŸtÄ±rma ve DoÄŸrulama (MantÄ±ksal Kontrol AdÄ±mÄ±)
EÄŸer cevap AdÄ±m 1'i geÃ§tiyse, ÅŸimdi `kabul_kriterleri` listesindeki her bir maddeyi bir mantÄ±ksal kural olarak ele al ve doÄŸrula:

* AdÄ±m 2a: MantÄ±ksal KurallarÄ± Yorumlama
    * VE (AND) KuralÄ±: EÄŸer bir kabul kriteri iÃ§inde `VE` operatÃ¶rÃ¼ varsa, bu, o kuralÄ±n geÃ§erli sayÄ±lmasÄ± iÃ§in TÃœM koÅŸullarÄ±n cevapta bulunmasÄ±nÄ±n ZORUNLU olduÄŸu anlamÄ±na gelir. Bir tanesi bile eksikse, o kural karÅŸÄ±lanmamÄ±ÅŸ sayÄ±lÄ±r.
    * VEYA (OR) KuralÄ±: EÄŸer bir kabul kriteri iÃ§inde `VEYA` operatÃ¶rÃ¼ varsa, bu, koÅŸullardan en az birinin cevapta bulunmasÄ±nÄ±n YETERLÄ° olduÄŸu anlamÄ±na gelir.
    * Basit Kural: EÄŸer bir kriterde `VE`/`VEYA` yoksa, o tek bir koÅŸul olarak deÄŸerlendirilir.

* AdÄ±m 2b: Karar Verme
    * `correct` KararÄ± Ä°Ã§in: CevabÄ±n `correct` sayÄ±labilmesi iÃ§in, `kabul_kriterleri` listesindeki en az bir ana mantÄ±ksal kuralÄ± tam olarak (yani iÃ§indeki tÃ¼m `VE` koÅŸullarÄ±yla birlikte) karÅŸÄ±lamasÄ± gerekir.
    * `wrong` KararÄ± Ä°Ã§in: EÄŸer cevap, `kabul_kriterleri` listesindeki hiÃ§bir ana mantÄ±ksal kuralÄ± tam olarak karÅŸÄ±lamÄ±yorsa, karar `wrong` olmalÄ±dÄ±r. Bu durum, cevabÄ±n hem tamamen yetersiz olmasÄ±nÄ± hem de "Eksik Bilgi KÃ¶r NoktasÄ±"nÄ± (yani bir `VE` kuralÄ±nÄ±n sadece bir kÄ±smÄ±nÄ± karÅŸÄ±lamasÄ±nÄ±) kapsar.

GEREKÃ‡E YAZMA KURALLARI (ZORUNLU):
GerekÃ§en, yukarÄ±daki algoritmayÄ± nasÄ±l uyguladÄ±ÄŸÄ±nÄ± yansÄ±tmalÄ±dÄ±r.

* `correct` ise: GerekÃ§en, Ã¶ÄŸrencinin karÅŸÄ±ladÄ±ÄŸÄ± temel kabul kriterini veya kuralÄ±nÄ± kÄ±saca Ã¶zetlemelidir.
    * Ã–rnek: "DoÄŸru: Cevap, 'tÃ¼m vinÃ§ tiplerini listeleme' kuralÄ±nÄ± karÅŸÄ±lamakta ve 'single drum', 'twin drum', 'electric' ve 'hydraulic' ifadelerini iÃ§ermektedir."

* `wrong` ise: GerekÃ§en, kararÄ±n nedenini (AdÄ±m 1 mi, AdÄ±m 2 mi) net bir ÅŸekilde belirtmelidir.
    * Ret Kriteri Tetiklendiyse (AdÄ±m 1): "YanlÄ±ÅŸ: Cevap, 'jet propulsion sistemi iÃ§in propeller kelimesi' ret kriterini doÄŸrudan tetiklemiÅŸtir."
    * MantÄ±ksal Kural KarÅŸÄ±lanmadÄ±ysa (AdÄ±m 2): "YanlÄ±ÅŸ: Cevap yetersiz Ã§Ã¼nkÃ¼ 'tÃ¼m can salÄ± tiplerini listeleme' kuralÄ±nÄ± karÅŸÄ±lamamaktadÄ±r; zorunlu olan 'freefall lifeboat' ifadesi eksiktir."
    * HiÃ§bir Kural KarÅŸÄ±lanmadÄ±ysa (AdÄ±m 2): "YanlÄ±ÅŸ: Cevap, beklenen kabul kriterlerinden hiÃ§birini (Ã¶rneÄŸin, vinÃ§ tipleri veya gÃ¼Ã§ kaynaklarÄ±) iÃ§ermediÄŸi iÃ§in konu dÄ±ÅŸÄ± veya tamamen yetersizdir."

ZORUNLU Ã‡IKTI FORMATI:
Ã‡Ä±ktÄ±n, kesinlikle ve sadece `{"results": [...], "reasonings": [...]}` formatÄ±nda geÃ§erli bir JSON olmalÄ±dÄ±r.
"""
    # --- DEÄžÄ°ÅžÄ°KLÄ°K BURADA BÄ°TÄ°YOR ---

    for i, batch_data in enumerate(batches):
        print(f"--- ParÃ§a {i+1}/{len(batches)} hazÄ±rlanÄ±yor... ---")
        
        batch_questions = [item[0] for item in batch_data]
        batch_rubrics = [item[1] for item in batch_data]
        batch_answers = [item[2] for item in batch_data]
        
        input_data = {
            "questions": batch_questions,
            "evaluation_rubrics": batch_rubrics,
            "student_answers": batch_answers
        }
        
        user_message_content = json.dumps(input_data, ensure_ascii=False, indent=2)
        tasks.append(_call_openai_chat_model(auditor_system_prompt, user_message_content))

    final_results = []
    final_reasonings = []

    try:
        assistant_batch_responses = await asyncio.gather(*tasks)

        for i, response_text in enumerate(assistant_batch_responses):
            try:
                cleaned_text = response_text.strip().strip('`').strip('json\n').strip()
                parsed_response = json.loads(cleaned_text)
                
                if (isinstance(parsed_response, dict) and 
                        "results" in parsed_response and 
                        "reasonings" in parsed_response):
                    
                    batch_results = parsed_response["results"]
                    batch_reasonings = parsed_response["reasonings"]
                    
                    if len(batch_results) != len(batches[i]) or len(batch_reasonings) != len(batches[i]):
                         print(f"UYARI: ParÃ§a {i+1} iÃ§in Asistan'dan beklenmedik sayÄ±da sonuÃ§/gerekÃ§e dÃ¶ndÃ¼.")
                         final_results.extend(["wrong"]* len(batches[i]))
                         final_reasonings.extend(["HatalÄ± batch boyutu nedeniyle geÃ§ersiz sayÄ±ldÄ±."] * len(batches[i]))
                    else:
                        print(f"--- ParÃ§a {i+1} BaÅŸarÄ±yla DeÄŸerlendirildi. ---")
                        for j, reasoning in enumerate(batch_reasonings):
                            print(f"  -> Karar='{batch_results[j]}', GerekÃ§e='{reasoning}'")
                        
                        final_results.extend(batch_results)
                        final_reasonings.extend(batch_reasonings)
                else:
                    print(f"UYARI: ParÃ§a {i+1} iÃ§in Asistan'dan beklenmedik formatta yanÄ±t.")
                    final_results.extend(["wrong"]* len(batches[i]))
                    final_reasonings.extend([f"Beklenmedik format: {response_text}"] * len(batches[i]))

            except json.JSONDecodeError:
                print(f"UYARI: ParÃ§a {i+1} iÃ§in Asistan'dan JSON olmayan yanÄ±t.")
                final_results.extend(["wrong"] * len(batches[i]))
                final_reasonings.extend([f"JSON olmayan yanÄ±t: {response_text}"] * len(batches[i]))
    
    except Exception as e:
        print(f"Cevap kontrolÃ¼ sÄ±rasÄ±nda kritik bir asyncio hatasÄ± oluÅŸtu: {e}")
        raise HTTPException(status_code=500, detail=f"Asistan gÃ¶revleri Ã§alÄ±ÅŸtÄ±rÄ±lÄ±rken bir hata oluÅŸtu: {e}")

    if len(final_results) != len(questions_with_topics):
        raise HTTPException(status_code=500, detail="DeÄŸerlendirme sonrasÄ± toplam sonuÃ§ sayÄ±sÄ±, soru sayÄ±sÄ±yla eÅŸleÅŸmiyor.")

    print("--- Toplu DeÄŸerlendirme TamamlandÄ±. ---")
    
    return {
        "results": final_results,
        "reasonings": final_reasonings
    }
